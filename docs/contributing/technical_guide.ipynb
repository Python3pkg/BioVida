{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Technical Description of BioVida  \n",
    "=================\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a technical description of how BioVida works.\n",
    "This information is only relevant if you wish to change the library in some way (e.g., submit a pull request).\n",
    "\n",
    "Broadly, this notebook is (or will be) divided into to three distinct sections, mirroring the key subpackages within BioVida itself. Namely, `images`, `genomics` and `diagnostics`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model to Classify Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``Images`` supackage of BioVida contains tools to both harvest a process biomedical image data.\n",
    "Some of this processing is solved using standard programming techniques (e.g., regular expressions to extract information from an image's caption). However, the classification of images on whether or not they are suitable for a machine learning dataset cannot be solved 'by hand'. This task requires machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BioVida solves this classification problem by using a Convolutional Neural Network (ConvNet), built using the [Keras](https://keras.io) deep learning library. What follows is a description of how this model was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the Model\n",
    "from biovida.images.models.img_classification import ImageRecognitionCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the model, we must now define how many 'epochs' we wish to run \n",
    "as well as the location of the training and validation data.*\n",
    "\n",
    "*Note: a list of URLs for these images will be provided in the near feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "data_path = '/path/to/the/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is easy.\n",
    "We first create an instance of tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ircnn = ImageRecognitionCNN(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ircnn.conv_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ircnn.fit(nb_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we simply save what it has learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = '/path/to/the/data'\n",
    "ircnn.save(\"model_weights\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weights are then distributed with the package and used to identify images which may not be suitable to be included in the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing The Model\n",
    "\n",
    "---\n",
    "`Keras` also makes use of some very nice tools for visualizing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot # pip3 install pydot-ng\n",
    "plot(ircnn.model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image will be added when the model architecture is stabilized**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}